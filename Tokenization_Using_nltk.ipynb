{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN9Y+oiNb/xoHFIn4kZAaJA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Text Pre-processing using NLTK**"],"metadata":{"id":"Ezf90XGJ0Jiq"}},{"cell_type":"markdown","source":["# Tokenization"],"metadata":{"id":"tPVA5vxv0L9r"}},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt')\n","from nltk.tokenize import sent_tokenize\n","from nltk.tokenize import word_tokenize"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PmylfPVY0nnZ","executionInfo":{"status":"ok","timestamp":1663264688662,"user_tz":-330,"elapsed":1100,"user":{"displayName":"Md Rahmat","userId":"13664470893307141079"}},"outputId":"79bd2a2b-a1fb-4d5d-89df-767697ab2822"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}]},{"cell_type":"code","source":["str = \"The purpose of a grammar is to give an explicit description of a language. But the way in which we think of a grammar is closely intertwined with what we consider to be a language. Is it a large but finite set of observed utterances and written texts? Is it something more abstract like the implicit knowledge that competent speakers have about grammatical sentences? Or is it some combination of the two? We won't take a stand on this issue, but instead will introduce the main approaches.\""],"metadata":{"id":"2e7Tx5hB1ob3","executionInfo":{"status":"ok","timestamp":1663264688664,"user_tz":-330,"elapsed":23,"user":{"displayName":"Md Rahmat","userId":"13664470893307141079"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["print (sent_tokenize(str))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xLjodmU41rcX","executionInfo":{"status":"ok","timestamp":1663264688665,"user_tz":-330,"elapsed":21,"user":{"displayName":"Md Rahmat","userId":"13664470893307141079"}},"outputId":"1c5c5dcc-2d87-4c9e-93f1-b7b048062d5c"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["['The purpose of a grammar is to give an explicit description of a language.', 'But the way in which we think of a grammar is closely intertwined with what we consider to be a language.', 'Is it a large but finite set of observed utterances and written texts?', 'Is it something more abstract like the implicit knowledge that competent speakers have about grammatical sentences?', 'Or is it some combination of the two?', \"We won't take a stand on this issue, but instead will introduce the main approaches.\"]\n"]}]},{"cell_type":"code","source":["print (word_tokenize(str))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lb5LvXlC1uPO","executionInfo":{"status":"ok","timestamp":1663264689116,"user_tz":-330,"elapsed":466,"user":{"displayName":"Md Rahmat","userId":"13664470893307141079"}},"outputId":"d0f32fd9-56ca-4e11-e399-277be45cbb57"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["['The', 'purpose', 'of', 'a', 'grammar', 'is', 'to', 'give', 'an', 'explicit', 'description', 'of', 'a', 'language', '.', 'But', 'the', 'way', 'in', 'which', 'we', 'think', 'of', 'a', 'grammar', 'is', 'closely', 'intertwined', 'with', 'what', 'we', 'consider', 'to', 'be', 'a', 'language', '.', 'Is', 'it', 'a', 'large', 'but', 'finite', 'set', 'of', 'observed', 'utterances', 'and', 'written', 'texts', '?', 'Is', 'it', 'something', 'more', 'abstract', 'like', 'the', 'implicit', 'knowledge', 'that', 'competent', 'speakers', 'have', 'about', 'grammatical', 'sentences', '?', 'Or', 'is', 'it', 'some', 'combination', 'of', 'the', 'two', '?', 'We', 'wo', \"n't\", 'take', 'a', 'stand', 'on', 'this', 'issue', ',', 'but', 'instead', 'will', 'introduce', 'the', 'main', 'approaches', '.']\n"]}]},{"cell_type":"markdown","source":["TreebankWordTokenizer"],"metadata":{"id":"yenIHD3019Cg"}},{"cell_type":"code","source":["from nltk.tokenize import TreebankWordTokenizer\n","tokenizer = TreebankWordTokenizer()\n","tokenizer.tokenize('Hello World.')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"anTkPABu142n","executionInfo":{"status":"ok","timestamp":1663264689118,"user_tz":-330,"elapsed":35,"user":{"displayName":"Md Rahmat","userId":"13664470893307141079"}},"outputId":"817b135b-c33b-4231-a974-1c358c7b731c"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Hello', 'World', '.']"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["WordPunctTokenizer"],"metadata":{"id":"uOiplM6c1-eO"}},{"cell_type":"code","source":["from nltk.tokenize import WordPunctTokenizer\n","tokenizer = WordPunctTokenizer()\n","tokenizer.tokenize(\"Can't is a Contraction.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BWkaSM4V2AYY","executionInfo":{"status":"ok","timestamp":1663264689118,"user_tz":-330,"elapsed":30,"user":{"displayName":"Md Rahmat","userId":"13664470893307141079"}},"outputId":"28e18929-0569-4d8c-d146-d89057004809"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Can', \"'\", 't', 'is', 'a', 'Contraction', '.']"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["from nltk.tokenize import TreebankWordTokenizer\n","tokenizer = TreebankWordTokenizer()\n","tokenizer.tokenize(\"Can't is a Contraction.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tiy4wr-02QIA","executionInfo":{"status":"ok","timestamp":1663264689119,"user_tz":-330,"elapsed":27,"user":{"displayName":"Md Rahmat","userId":"13664470893307141079"}},"outputId":"13b88d93-1845-43c9-87af-9b019fb5dcd0"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Ca', \"n't\", 'is', 'a', 'Contraction', '.']"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["RegexpTokenizer"],"metadata":{"id":"fusNOz7p2Yxl"}},{"cell_type":"code","source":["from nltk.tokenize import RegexpTokenizer\n","tokenizer = RegexpTokenizer(\"[\\w']+\")\n","tokenizer.tokenize(\"Can't is a Contraction.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kDlhKFBu2ZlV","executionInfo":{"status":"ok","timestamp":1663264689120,"user_tz":-330,"elapsed":23,"user":{"displayName":"Md Rahmat","userId":"13664470893307141079"}},"outputId":"a5300849-59fd-41e4-b0c0-a6bad6c51d95"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[\"Can't\", 'is', 'a', 'Contraction']"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["from nltk.tokenize import RegexpTokenizer\n","tokenizer = RegexpTokenizer(\"[\\w']+\")\n","tokenizer.tokenize(\"abc@gmail.com\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e0IHW7Ia2dxN","executionInfo":{"status":"ok","timestamp":1663264689121,"user_tz":-330,"elapsed":20,"user":{"displayName":"Md Rahmat","userId":"13664470893307141079"}},"outputId":"e0c89403-658c-4738-9139-f074acc5e645"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['abc', 'gmail', 'com']"]},"metadata":{},"execution_count":9}]}]}