{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"17tB5av0GCq4n8qlD17CquzXNt_pGMUsz","timestamp":1663238083094}],"collapsed_sections":[],"authorship_tag":"ABX9TyPl71L7SubZFKC2HyaDrb0I"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Text Pre-processing using NLTK**"],"metadata":{"id":"Ezf90XGJ0Jiq"}},{"cell_type":"markdown","source":["# Lemmatization"],"metadata":{"id":"wZaXVdeq0YLZ"}},{"cell_type":"code","source":["import nltk\n","nltk.download('wordnet')\n","nltk.download('omw-1.4')\n","nltk.download('punkt')\n","\n","from nltk.stem import WordNetLemmatizer\n","wordnet_lemmatizer = WordNetLemmatizer()\n","text3 = \"I am Studying in Part 2.\"\n","tokenization = nltk.word_tokenize(text3)\n","for w in tokenization:\n","  print(\"Lemma for {} is {}\".format(w, wordnet_lemmatizer.lemmatize(w)))"],"metadata":{"id":"dVa1o6Ia2z6F","executionInfo":{"status":"ok","timestamp":1663264880287,"user_tz":-330,"elapsed":2871,"user":{"displayName":"Md Rahmat","userId":"13664470893307141079"}},"outputId":"6fd5e9a4-5181-4181-a33d-0bff37f38204","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n"]},{"output_type":"stream","name":"stdout","text":["Lemma for I is I\n","Lemma for am is am\n","Lemma for Studying is Studying\n","Lemma for in is in\n","Lemma for Part is Part\n","Lemma for 2 is 2\n","Lemma for . is .\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}]}]}